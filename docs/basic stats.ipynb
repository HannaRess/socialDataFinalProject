{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc3a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc6abdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location data set of the sensors.\n",
    "df_s = pd.read_csv('https://www.student.dtu.dk/~s212220/socialData2022/Data/Pedestrian_Counting_System_-_Sensor_Locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d55022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pedestrian data set\n",
    "df_p = pd.read_csv('https://www.student.dtu.dk/~s212220/socialData2022/Data/Pedestrian_Counting_System_-_Monthly__counts_per_hour_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68c3acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The weather data set\n",
    "df_w = pd.read_csv('https://www.student.dtu.dk/~s212220/socialData2022/Data/weather_melbourne.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285463f",
   "metadata": {},
   "source": [
    "### A short section on the dataset stats, containing key points/plots from our exploratory data analysis.\n",
    "\n",
    "Let's start with the location of the sensors. Here are some basic information about it:\n",
    "* 78 rows coresponding to the amount of sensors.\n",
    "* 10KB\n",
    "* 11 columns: only bold written columns will be used.\n",
    "    * **sensor_id**: integers from 1 to 79 correcponting to each row and sensor\n",
    "    * **sensor_description**: unique categories (78 values) which corespond to the street name the sensors are installed on\n",
    "    * sensor_name: categorial unique name (78 values) of the senor\n",
    "    * **installation_date**: dates when the sensor was installed, 60 different values from 2009/01/20 until 2021/09/10\n",
    "    * **status**: categorial (A = Active, I = Inactive, R = Removed), 71 sensors are active and 7 where removed\n",
    "    * note: categorial strings, notes on a sensor, 10 different values, the other 69 values are missing\n",
    "    * direction_1 & direction_2: categorial (North, South, West, East) the two directions the sensors are reading into. Both have 4 missing values\n",
    "    * **latitude**: distinct real numbers representing the latitude of the sensor, from -37.82401776 until -37.79453802\n",
    "    * **longitude**: distinct real numbers representing the longitude of the sensor, from 144.9303619 until 144.9746766\n",
    "    * location: 78 distinct values showing the latitude and longitude together.\n",
    "\n",
    "An imporant thing to notice is the status.  7 sensors were removed in the past due to construction work or something else. Since we assume that there were no futher data collected from the sensors after their removal, we can still leave them in the dataset. We always have to be aware that the amount of sensors collecting data changes over time. Either to new installed sensors or to removed ones. (While looking at the data points of the removed sensors, it states that 2 of them were removed in 2017, one in 2015 and for the other 4 is no information provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5ab100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s.drop(['sensor_name', 'note', 'direction_1', 'direction_2', 'location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468a4270",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folium' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lg/msc95s9d3kvb52s420_7y9b40000gn/T/ipykernel_31247/3306783838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The maps shows the location of the sensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m map_loc = folium.Map(location=[-37.8140000, 144.9633200],tiles = \"Stamen Toner\",\n\u001b[0m\u001b[1;32m      3\u001b[0m                     zoom_start = 14) \n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ensure you're handing it floats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folium' is not defined"
     ]
    }
   ],
   "source": [
    "# The maps shows the location of the sensors.\n",
    "map_loc = folium.Map(location=[-37.8140000, 144.9633200],tiles = \"Stamen Toner\",\n",
    "                    zoom_start = 14) \n",
    "\n",
    "# Ensure you're handing it floats\n",
    "df_s['latitude'] = df_s['latitude'].astype(float)\n",
    "df_s['longitude'] = df_s['longitude'].astype(float)\n",
    "\n",
    "for index, row in df_s.iterrows():\n",
    "    folium.Marker([row['latitude'], row['longitude']], popup=row['sensor_description']).add_to(map_loc)\n",
    "\n",
    "# Styling title\n",
    "loc = 'Corpus Christi'\n",
    "title_html = '''\n",
    "             <h3 align=\"center\" style=\"font-size:16px\"><b>Locations of Sensors</b></h3>\n",
    "             '''.format(loc) \n",
    "map_loc.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# Display the map\n",
    "map_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91592a7a",
   "metadata": {},
   "source": [
    "The interactive map shows all the locations of the different sensors collecting the pedestrian data. As visible, most of the sensors are located in the inner city and that's where our focus is directed in the project. Each of the sensors provides a description containing the street or corner where they are located. One outlineer can be noticed when zooming out on the map. It's the sensor located on the corner of Macaulay Rd and Bellair St. As we are focusing on the city center and - by having a look at the data - since it was installed at the end of the timeframe of our pedestrian data set on 2021/02/20, we still leave it in the data set but our later maps may not focus on showing it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b37f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the year of the installation\n",
    "df_s['Year'] = pd.DatetimeIndex(df_s['installation_date']).year\n",
    "# adding missing years in range(2009, 2022)\n",
    "df = pd.DataFrame({'Year': [2010, 2011, 2012, 2016]})\n",
    "df_s_y = df_s.append(df, ignore_index = True)\n",
    "\n",
    "# Plot that shows new introduced sensors per year\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "df_s_y.groupby(['Year']).count()['sensor_id'].plot \\\n",
    "    .bar(title='New Installed Sensors per Year', x=range(df_s['Year'].min(),df_s['Year'].max() + 1),\n",
    "         edgecolor='darkgreen', color = 'green')\n",
    "# Styling\n",
    "plt.ylabel('Number of New Installed Sensors');\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8748c",
   "metadata": {},
   "source": [
    "The plot aboth shows when sensors were installed over the years. Covid is a pendemic which hit Melbourne in March 2020 [Source](https://en.wikipedia.org/wiki/COVID-19_pandemic_in_Victoria). Until then there were 61 sensors installed. In the futher analytics we will focus on 2019 as a year before covid and 2020 as a representativ of covid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7018c",
   "metadata": {},
   "source": [
    "Next up, we are providing some important insights to the pedestrian data we used:\n",
    "* 4176218 rows corresponding to data collected in an hour with one sensor.\n",
    "* 396.8MB\n",
    "* 10 columns: only bold written columns will be used.\n",
    "    * ID: distinct number representing a unique id of the data point from 1 to 4181689\n",
    "    * Date_Time: categorial string value representing the date and time the data point was collected\n",
    "    * **Year**: 16 different number values representing the year when the data point was collected, from 2009 until 2022\n",
    "    * **Month**: 12 categorial string values representing the month of the year.\n",
    "    * **Mdate**: 31 integers from 1 until 31 representing the date of the month.\n",
    "    * **Day**: 7 categorial string values representing the day of the week.\n",
    "    * **Time**: 23 integers representing the starting time of the day the data was collected for an hour.\n",
    "    * **Sensor_ID**: 81 different integers representing the ID of the sensor collecting the data. Reference to the sensor location data set.\n",
    "    * Sensor_Name: categorial unique name (93 values) of the senor collecting the data\n",
    "    * **Hourly_Counts**: 6359 different numbers representing the total amount of pedestrians counted during this hour form 0 to 15979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unused columns\n",
    "df_p.drop(['ID', 'Date_Time', 'Sensor_Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0115ee55",
   "metadata": {},
   "source": [
    "With this information, we can see that there is a difference in amount of Sensor_ID and Sensor_Name which should not happen. Since it is only the name which probably relates to a different naming and we do not need this column, we are not looking deeper into that. \n",
    "\n",
    "More interesting is the difference between the sensor ids of the pedestrian dataset and the sensor location data set. Let's have a look at that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the 3 missing sensors\n",
    "for s_id in df_p.Sensor_ID.unique():\n",
    "    if s_id not in df_s.sensor_id.unique():\n",
    "        print('Sensor ID: ', s_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50199b68",
   "metadata": {},
   "source": [
    "A we can see, the sensor ids 84, 85 and 86 are not appearing in the sensor location data set. We decided to drop the data points collected with these sencors since we are not having enouth information about the senors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73054d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the pedestrian data - deleting the missing sensors activity\n",
    "df_p = df_p[(df_p.Sensor_ID != 84) & (df_p.Sensor_ID != 85) & (df_p.Sensor_ID != 86)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot shows the data points over the year and the amount of pedestrians walking\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
    "df_p.groupby('Year').count()['ID'].plot \\\n",
    "    .bar(title='Data points over the Years\\n', \n",
    "         ax = ax[0], edgecolor='darkgreen', color = 'green')\n",
    "df_p.groupby(['Year']).sum()['Hourly_Counts'].plot \\\n",
    "    .bar(title='Amount of Pedestrians on the Street per Year\\n', \n",
    "         ax=ax[1], edgecolor='darkgreen', color = 'green')\n",
    "\n",
    "# Styling\n",
    "ax[0].set_ylabel('Num of Data Points');\n",
    "ax[1].set_ylabel('Total Amount of Pedestrians');\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4d483",
   "metadata": {},
   "source": [
    "The collection of data grew over the years for the pedestrian data set. This can be compared with the plot aboth showing the installed sensors. Whenever no new sensors where installed, the collection of data languishs. The amount of pedestrians on the street is mainly growing due to more datapoints but we can see a few unexpected outliners. Looking at 2020 and 2021, we can see a huge drop in the amount of pedestrians on the street while the data points are growing which is due to covid. \n",
    "Another small drop can be observed in 2017 which is probably due to the sensors which were removed during that year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d0edd",
   "metadata": {},
   "source": [
    "Finally, we are digging deeper into the weather data set:\n",
    "* 2557 rows corresponding to each day\n",
    "* 114KB\n",
    "* 11 columns: only bold written columns will be used.\n",
    "    * **date**: distinct categorial value representing the date the data point was collected form 2015/01/01 until 2021/12/31\n",
    "    * **tavg**: 251 different real numbers representing the average temperature on that day from 4.6 to 34.3 °C\n",
    "    * **tmin**: 230 different real numbers representing the minimum temperature on that day from -2 to 26.5 °C\n",
    "    * **tmax**: 305 different real numbers representing the maximum temperature on that day from 8.3 to 46 °C\n",
    "    * **prcp**: 120 different real numbers representing the percipitation on that day from 0 to 69 mm\n",
    "    * snow: completly missing\n",
    "    * **wdir**: 277 different real numbers representing the wind direction on that day from 0 to 360 degrees, 160 missing values\n",
    "    * **wspd**: 343 different real numbers representing the wind speed on that day from 3.8 to 55.3 km/h, 21 missing values\n",
    "    * wpgt: comletly missing\n",
    "    * pres: 358 different real numbers representing the air pressure on that day from 962.2 to 1036.1 hPa, 350 missing values\n",
    "    * tsun: completly missing\n",
    "    \n",
    "Due to either comletly missing all values or not enouth values (14% missing), we decided to drop the columns which are not written in bold. Since we still have some missing values, we will drop the rows having missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c8b8800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-12-31'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the weather data - dropping snow, wpgt, tsun, pres due to too many missing values\n",
    "df_w = df_w.drop(['snow', 'wpgt', 'pres', 'tsun'], axis=1)\n",
    "# Drop NaN values of the rest of the culomns\n",
    "df_w = df_w.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "# Prefparing the weather data\n",
    "df_w['Year'] = pd.DatetimeIndex(df_w['date']).year\n",
    "df_w['MonthNo'] = pd.DatetimeIndex(df_w['date']).month\n",
    "df_w['Month'] = df_w['MonthNo'].apply(lambda x: months[x-1])\n",
    "\n",
    "# Creating plots with basic statistics for temperature, wind-speed and percipitation\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(13,7))\n",
    "df_w['Month'] = pd.Categorical(df_w['Month'], categories=months, ordered=True)\n",
    "\n",
    "featuresToPlot = ['prcp','wspd','tavg']\n",
    "titleLabels = ['precipitation','wind-speed','temperature']\n",
    "colors = ['blue','grey','red']\n",
    "yUnits = ['mm','km / h','C°']\n",
    "for n, f in enumerate(featuresToPlot):\n",
    "    df_w.groupby(df_w['Year']).mean()[f].plot.bar(color = colors[n],title=f'Average {titleLabels[n]} over years', ax = ax[(int(n/3)),(int(n%3))])\n",
    "    ax[(int(n/3)),(int(n%3))].set_ylabel(yUnits[n]) \n",
    "    \n",
    "for n, f in enumerate(featuresToPlot):\n",
    "    df_w.groupby(df_w['Month']).mean()[f].plot.bar(color = colors[n],title=f'Average {titleLabels[n]} over months', ax = ax[(int((n+3)/3)),(int((n+3)%3))])\n",
    "    ax[(int((n+3)/3)),(int((n+3)%3))].set_ylabel(yUnits[n]) \n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf7529",
   "metadata": {},
   "source": [
    "By looking at a few basic plots of the weather data, we can see that 2015 and 2019 where quite dry years. Looking at the rain over months, it reveals a rather unusual structure since there are some hugh drops. We din't expect that but we think its just how weather is. Not always as expected. The other plots show that Melbourne has quite static weather weather over the years with a normal distribution over the months."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
